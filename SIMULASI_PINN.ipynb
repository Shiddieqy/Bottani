{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBBOTgeBdcxU8SYpv4azh7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shiddieqy/Bottani/blob/main/SIMULASI_PINN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWh7iqiqY-In",
        "outputId": "ec5f0dce-ce87-47cf-dc2b-4b366f1f8417"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.gridspec as gridspec\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "np.random.seed(1234)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lWuYF2wueCyw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA support\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzKSFzlHdazh",
        "outputId": "2501c1f4-cef3-48e4-a4e2-58da0458c712"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#variables\n",
        "mp=torch.tensor(1.0).float().to(device)\n",
        "mt=torch.tensor(1.0).float().to(device)\n",
        "gr=torch.tensor(9.8).float().to(device)\n",
        "\n",
        "hlf=torch.tensor(0.5).float().to(device)\n",
        "uni=torch.tensor(1.0).float().to(device)\n",
        "zr=torch.tensor(0.0).float().to(device)\n",
        "c_lyp=torch.tensor(0.0001).float().to(device)\n",
        "b_lyp=torch.tensor(0.1).float().to(device)\n",
        "R= torch.zeros((6,6)).float().to(device)\n",
        "\n",
        "xd=torch.tensor(1.0).float().to(device)\n",
        "ld=torch.tensor(1.0).float().to(device)"
      ],
      "metadata": {
        "id": "yc1KsWHn5Lvc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U9bHpCGHY3H4"
      },
      "outputs": [],
      "source": [
        "# the deep neural network\n",
        "class DNN(torch.nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super(DNN, self).__init__()\n",
        "\n",
        "        # parameters\n",
        "        self.depth = len(layers) - 1\n",
        "\n",
        "        # set up layer order dict\n",
        "        self.activation = torch.nn.Tanh\n",
        "\n",
        "        layer_list = list()\n",
        "        for i in range(self.depth - 1):\n",
        "            layer_list.append(\n",
        "                ('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1]))\n",
        "            )\n",
        "            layer_list.append(('activation_%d' % i, self.activation()))\n",
        "\n",
        "        layer_list.append(\n",
        "            ('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1]))\n",
        "        )\n",
        "        layerDict = OrderedDict(layer_list)\n",
        "\n",
        "        # deploy layers\n",
        "        self.layers = torch.nn.Sequential(layerDict)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelh = torch.load(\"/content/drive/MyDrive/Prof Bayu Groningen/modelRTGCPINNErrorL_E2&E5000_greaterdeg105_CL.pt\")\n",
        "modelh.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTKxwA_DeFMN",
        "outputId": "58a282e8-3a97-45fa-a92a-27e11f883513"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DNN(\n",
              "  (layers): Sequential(\n",
              "    (layer_0): Linear(in_features=12, out_features=20, bias=True)\n",
              "    (activation_0): Tanh()\n",
              "    (layer_1): Linear(in_features=20, out_features=20, bias=True)\n",
              "    (activation_1): Tanh()\n",
              "    (layer_2): Linear(in_features=20, out_features=20, bias=True)\n",
              "    (activation_2): Tanh()\n",
              "    (layer_3): Linear(in_features=20, out_features=19, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xdat = torch.tensor([0,0,1,0,0,0,0,1,1,0,0,0],dtype=torch.float32, requires_grad=True).to(device)\n",
        "X = torch.tensor([1,2,1,0,0,0],dtype=torch.float32, requires_grad=True).to(device)\n",
        "Ha = modelh(xdat)"
      ],
      "metadata": {
        "id": "A9OGcxxfeOEY"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Ha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31ZeC_3de3BY",
        "outputId": "9f613709-000b-41ef-ff51-527d1cbbe3a2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 9.4621,  0.7816,  0.4968, -0.8280, -0.1704,  0.1826, -0.4597, -0.2600,\n",
            "        -0.0973, -0.4642, -0.9170,  0.4350, -0.1108, -0.6870,  0.5383,  0.3521,\n",
            "         0.1728,  0.4639,  1.4321], device='cuda:0', grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Hamiltonian(Xf):\n",
        "\n",
        "      tet =Xf[0]\n",
        "      x = Xf[1]\n",
        "      l = Xf[2]\n",
        "      ptet = Xf[3]\n",
        "      px = Xf[4]\n",
        "      pl = Xf[5]\n",
        "\n",
        "\n",
        "      M00=mp*torch.square(l)\n",
        "      M00=M00.reshape(1)\n",
        "      M01=mp*torch.mul(l,torch.cos(tet))\n",
        "      M01 = M01.reshape(1)\n",
        "      M02=torch.zeros(tet.shape).float().to(device)\n",
        "      M02 = M02.reshape(1)\n",
        "\n",
        "      M10=mp*torch.mul(l,torch.cos(tet))\n",
        "      # M10=torch.reshape(M10,(tet.shape[0],1))\n",
        "      M11=torch.Tensor(mt+ mp)\n",
        "      # M11=torch.reshape(M11,(tet.shape[0],1))\n",
        "      M12=mp*torch.sin(tet)\n",
        "      # M12=torch.reshape(M12,(tet.shape[0],1))\n",
        "\n",
        "      M20=torch.zeros(tet.shape).float().to(device)\n",
        "      # M20=torch.reshape(M20,(tet.shape[0],1))\n",
        "      M21=mp*torch.sin(tet)\n",
        "      # M21=torch.reshape(M21,(tet.shape[0],1))\n",
        "      M22=torch.Tensor(mp)\n",
        "      # M22=torch.reshape(M22,(tet.shape[0],1))\n",
        "      M10 = M10.reshape(1)\n",
        "      M11 = M11.reshape(1)\n",
        "      M12 = M12.reshape(1)\n",
        "      M20 = M20.reshape(1)\n",
        "      M21 = M21.reshape(1)\n",
        "      M22 = M22.reshape(1)\n",
        "\n",
        "      # print(M00.shape)\n",
        "      #Mass Matrix and Its inverse\n",
        "\n",
        "      M0=torch.cat([M00,M01,M02])\n",
        "      M1=torch.cat([M10, M11, M12])\n",
        "      M2=torch.cat([M20, M21, M22])\n",
        "      M=torch.cat([M0,M1,M2])\n",
        "      M=torch.reshape(M,(3,3))\n",
        "\n",
        "\n",
        "      Minv=torch.linalg.inv(M)\n",
        "      ptet = ptet.reshape(1)\n",
        "      px = px.reshape(1)\n",
        "      pl = pl.reshape(1)\n",
        "      p = torch.cat([ptet, px, pl],0)\n",
        "      p = torch.reshape(p,(1,3))\n",
        "\n",
        "      pT=torch.t(p)\n",
        "\n",
        "\n",
        "      H=hlf*torch.matmul((torch.matmul(p, Minv)),pT)+mp*gr*l*(uni-torch.cos(tet))\n",
        "      dH = torch.autograd.grad(\n",
        "    H, px,\n",
        "    grad_outputs=torch.ones_like(H),\n",
        "    retain_graph=True,\n",
        "    create_graph=True\n",
        "    )[0]\n",
        "      print(dH)\n",
        "\n",
        "\n",
        "      return H\n"
      ],
      "metadata": {
        "id": "eRQPZ9ro4u23"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "H = Hamiltonian(X)\n",
        "\n",
        "Hd = H+ Ha + torch.square(X[1]- xd).view(H.shape) + torch.square(X[2]- ld).view(H.shape)\n",
        "\n",
        "\n",
        "dH = torch.autograd.grad(\n",
        "    H, X,\n",
        "    grad_outputs=torch.ones_like(H),\n",
        "    retain_graph=True,\n",
        "    create_graph=True\n",
        ")[0]\n",
        "dHd = torch.autograd.grad(\n",
        "    Hd, X,\n",
        "    grad_outputs=torch.ones_like(Hd),\n",
        "    retain_graph=True,\n",
        "    create_graph=True\n",
        ")[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGcEG6rZ7A7W",
        "outputId": "c12f7db7-5099-4e34-9007-e7e6fdc0efa5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.], device='cuda:0', grad_fn=<SliceBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dH,dHd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "auL2mfbDAVQ3",
        "outputId": "9e04e9ac-84f8-403f-874c-8f2b1d29f10c"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8.2464, 0.0000, 4.5050, 0.0000, 0.0000, 0.0000], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>) tensor([156.6819,  38.0000,  85.5957,   0.0000,   0.0000,   0.0000],\n",
            "       device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    }
  ]
}